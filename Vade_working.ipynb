{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "v2DOVQNNlkBW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "from torch.optim import Adam\n",
        "import itertools\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "\n",
        "def get_data(data=\"MNIST\", batch_size=128):\n",
        "    # Datasets loading\n",
        "    data_dir = f\"./data/{data}/\"\n",
        "    if data == \"MNIST\":\n",
        "        train_dataset = datasets.MNIST(\n",
        "            root=\"./mnist_data/\",\n",
        "            train=True,\n",
        "            transform=transforms.Compose(\n",
        "                [transforms.ToTensor(), transforms.Lambda(torch.flatten)]\n",
        "            ),\n",
        "            download=True,\n",
        "        )\n",
        "        test_dataset = datasets.MNIST(\n",
        "            root=\"./mnist_data/\",\n",
        "            train=False,\n",
        "            transform=transforms.Compose(\n",
        "                [transforms.ToTensor(), transforms.Lambda(torch.flatten)]\n",
        "            ),\n",
        "            download=False,\n",
        "        )\n",
        "    elif data == \"FashionMNIST\":\n",
        "        train_dataset = datasets.FashionMNIST(\n",
        "            root=\"./mnist_data/\",\n",
        "            train=True,\n",
        "            transform=transforms.Compose(\n",
        "                [transforms.ToTensor(), transforms.Lambda(torch.flatten)]\n",
        "            ),\n",
        "            download=True,\n",
        "        )\n",
        "        test_dataset = datasets.FashionMNIST(\n",
        "            root=\"./mnist_data/\",\n",
        "            train=False,\n",
        "            transform=transforms.Compose(\n",
        "                [transforms.ToTensor(), transforms.Lambda(torch.flatten)]\n",
        "            ),\n",
        "            download=False,\n",
        "        )\n",
        "    # Data Loader (Input Pipeline)\n",
        "    train_loader = DataLoader(\n",
        "        dataset=train_dataset, batch_size=batch_size, shuffle=True\n",
        "    )\n",
        "    test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "    return train_loader, test_loader\n",
        "\n",
        "\n",
        "def get_hidden_layer(in_dim, out_dim):\n",
        "    return [nn.Linear(in_dim, out_dim), nn.ReLU(True)]\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim=784, hidden_dims=[512, 512, 2048], stat_dim=10):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.mu_l = nn.Linear(hidden_dims[-1], stat_dim)\n",
        "        self.log_sigma2_l = nn.Linear(hidden_dims[-1], stat_dim)\n",
        "        self.encoder = nn.Sequential(\n",
        "            *get_hidden_layer(input_dim, hidden_dims[0]),\n",
        "            *get_hidden_layer(hidden_dims[0], hidden_dims[1]),\n",
        "            *get_hidden_layer(hidden_dims[1], hidden_dims[2]),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        e = self.encoder(x)\n",
        "        return self.mu_l(e), self.log_sigma2_l(e)\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_dim=784, hidden_dims=[512, 512, 2048], stat_dim=10):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.decoder = nn.Sequential(\n",
        "            *get_hidden_layer(stat_dim, hidden_dims[-1]),\n",
        "            *get_hidden_layer(hidden_dims[-1], hidden_dims[-2]),\n",
        "            *get_hidden_layer(hidden_dims[-2], hidden_dims[-3]),\n",
        "            nn.Linear(hidden_dims[-3], input_dim),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        x_pro = self.decoder(z)\n",
        "        return x_pro\n",
        "\n",
        "\n",
        "class VaDE(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_clusters,\n",
        "        stat_dim,\n",
        "        hidden_dims=[512, 512, 2048],\n",
        "        input_dim=784,\n",
        "        cuda=True,\n",
        "    ):\n",
        "        super(VaDE, self).__init__()\n",
        "        self.n_clusters = n_clusters\n",
        "        self.stat_dim = stat_dim\n",
        "        self.cuda = torch.cuda.is_available() and cuda\n",
        "        self.encoder = Encoder(\n",
        "            input_dim=input_dim, hidden_dims=hidden_dims, stat_dim=stat_dim\n",
        "        )\n",
        "        self.decoder = Decoder(\n",
        "            input_dim=input_dim, hidden_dims=hidden_dims, stat_dim=stat_dim\n",
        "        )\n",
        "        self.pi_ = nn.Parameter(\n",
        "            torch.FloatTensor(\n",
        "                self.n_clusters,\n",
        "            ).fill_(1)\n",
        "            / self.n_clusters,\n",
        "            requires_grad=True,\n",
        "        )\n",
        "        self.mu_c = nn.Parameter(\n",
        "            torch.FloatTensor(self.n_clusters, self.stat_dim).fill_(0),\n",
        "            requires_grad=True,\n",
        "        )\n",
        "        self.log_sigma2_c = nn.Parameter(\n",
        "            torch.FloatTensor(self.n_clusters, self.stat_dim).fill_(0),\n",
        "            requires_grad=True,\n",
        "        )\n",
        "        if self.cuda:\n",
        "            self = self.cuda()\n",
        "            self = nn.DataParallel(self, device_ids=range(4))\n",
        "\n",
        "    def pre_train(self, dataloader, pre_epoch=10):\n",
        "        if not os.path.exists(\"./pretrained_model.pk\"):\n",
        "            Loss_fn = nn.MSELoss()\n",
        "            opti = Adam(\n",
        "                itertools.chain(self.encoder.parameters(), self.decoder.parameters())\n",
        "            )\n",
        "            print(\"Pretraining......\")\n",
        "            epoch_bar = tqdm(range(pre_epoch))\n",
        "            for _ in epoch_bar:\n",
        "                L = 0\n",
        "                for x, y in dataloader:\n",
        "                    if self.cuda:\n",
        "                        x = x.cuda()\n",
        "\n",
        "                    z, _ = self.encoder(x)\n",
        "                    x_ = self.decoder(z)\n",
        "                    loss = Loss_fn(x, x_)\n",
        "\n",
        "                    L += loss.detach().cpu().numpy()\n",
        "\n",
        "                    opti.zero_grad()\n",
        "                    loss.backward()\n",
        "                    opti.step()\n",
        "                epoch_bar.write(\"L2={:.4f}\".format(L / len(dataloader)))\n",
        "            self.encoder.log_sigma2_l.load_state_dict(self.encoder.mu_l.state_dict())\n",
        "            Z = []\n",
        "            Y = []\n",
        "            with torch.no_grad():\n",
        "                for x, y in dataloader:\n",
        "                    if self.cuda:\n",
        "                        x = x.cuda()\n",
        "                    z1, z2 = self.encoder(x)\n",
        "                    assert F.mse_loss(z1, z2) == 0\n",
        "                    Z.append(z1)\n",
        "                    Y.append(y)\n",
        "            Z = torch.cat(Z, 0).detach().cpu().numpy()\n",
        "            Y = torch.cat(Y, 0).detach().numpy()\n",
        "            gmm = GaussianMixture(n_components=self.n_clusters, covariance_type=\"diag\")\n",
        "            pre = gmm.fit_predict(Z)\n",
        "            if self.cuda:\n",
        "                self.pi_.data = torch.from_numpy(gmm.weights_).cuda().float()\n",
        "                self.mu_c.data = torch.from_numpy(gmm.means_).cuda().float()\n",
        "                self.log_sigma2_c.data = torch.log(\n",
        "                    torch.from_numpy(gmm.covariances_).cuda().float()\n",
        "                )\n",
        "            else:\n",
        "                self.pi_.data = torch.from_numpy(gmm.weights_).float()\n",
        "                self.mu_c.data = torch.from_numpy(gmm.means_).float()\n",
        "                self.log_sigma2_c.data = torch.log(\n",
        "                    torch.from_numpy(gmm.covariances_).float()\n",
        "                )\n",
        "            torch.save(self.state_dict(), \"./pretrained_model.pk\")\n",
        "        else:\n",
        "            self.load_state_dict(torch.load(\"./pretrained_model.pk\"))\n",
        "\n",
        "    def train(self, dataloader, epochs=100, lr=2e-3, gamma=0.95):\n",
        "        opti = Adam(self.parameters(), lr=lr)\n",
        "        lr_s = StepLR(opti, step_size=10, gamma=gamma)\n",
        "        writer = SummaryWriter(\"./logs\")\n",
        "        epoch_bar = tqdm(range(epochs))\n",
        "        for epoch in epoch_bar:\n",
        "            L = 0\n",
        "            for x, _ in dataloader:\n",
        "                if self.cuda:\n",
        "                    x = x.cuda()\n",
        "                loss = vade.ELBO_Loss(x)\n",
        "                opti.zero_grad()\n",
        "                loss.backward()\n",
        "                opti.step()\n",
        "                L += loss.detach().cpu().numpy()\n",
        "            lr_s.step()\n",
        "            writer.add_scalar(\"loss\", L / len(DL), epoch)\n",
        "            writer.add_scalar(\"lr\", lr_s.get_last_lr()[0], epoch)\n",
        "            epoch_bar.write(\n",
        "                \"Loss={:.4f},LR={:.4f}\".format(L / len(DL), lr_s.get_last_lr()[0])\n",
        "            )\n",
        "\n",
        "    def predict_proba(self, x):\n",
        "        z_mu, z_sigma2_log = self.encoder(x)\n",
        "        z = torch.randn_like(z_mu) * torch.exp(z_sigma2_log / 2) + z_mu\n",
        "        y_c = torch.exp(\n",
        "            torch.log(self.pi_.unsqueeze(0))\n",
        "            + self.gaussian_pdfs_log(z)\n",
        "        )\n",
        "        return y_c\n",
        "    def predict(self, x):\n",
        "        y_c = self.predict_proba(x)\n",
        "        y = y_c.detach().cpu().numpy()\n",
        "        return np.argmax(y, axis=1)\n",
        "\n",
        "    def ELBO_Loss(self, x, L=1, det=1e-10):\n",
        "        L_rec = 0\n",
        "        z_mu, z_sigma2_log = self.encoder(x)\n",
        "        for l in range(L):\n",
        "            z = torch.randn_like(z_mu) * torch.exp(z_sigma2_log / 2) + z_mu\n",
        "            x_pro = self.decoder(z)  # x_pro sometimes has nans\n",
        "            try:\n",
        "                L_rec += F.binary_cross_entropy(x_pro, x)\n",
        "            except:\n",
        "                print(x_pro.min(), x_pro.max())\n",
        "        L_rec = L_rec / L\n",
        "        Loss = L_rec * x.size(1)\n",
        "        z = torch.randn_like(z_mu) * torch.exp(z_sigma2_log / 2) + z_mu\n",
        "        y_c = (\n",
        "            torch.exp(\n",
        "                torch.log(self.pi_.unsqueeze(0))\n",
        "                + self.gaussian_pdfs_log(z)\n",
        "            )\n",
        "            + det\n",
        "        )\n",
        "        y_c = y_c / (y_c.sum(1).view(-1, 1))  # batch_size*Clusters\n",
        "        Loss += 0.5 * torch.mean(\n",
        "            torch.sum(\n",
        "                y_c\n",
        "                * torch.sum(\n",
        "                    self.log_sigma2_c.unsqueeze(0)\n",
        "                    + torch.exp(\n",
        "                        z_sigma2_log.unsqueeze(1) - self.log_sigma2_c.unsqueeze(0)\n",
        "                    )\n",
        "                    + (z_mu.unsqueeze(1) - self.mu_c.unsqueeze(0)).pow(2)\n",
        "                    / torch.exp(self.log_sigma2_c.unsqueeze(0)),\n",
        "                    2,\n",
        "                ),\n",
        "                1,\n",
        "            )\n",
        "        )\n",
        "        Loss -= torch.mean(\n",
        "            torch.sum(y_c * torch.log(self.pi_.unsqueeze(0) / (y_c)), 1)\n",
        "        ) + 0.5 * torch.mean(torch.sum(1 + z_sigma2_log, 1))\n",
        "        return Loss\n",
        "\n",
        "    def gaussian_pdfs_log(self, x):\n",
        "        G = []\n",
        "        for c in range(self.n_clusters):\n",
        "            G.append(\n",
        "                self.gaussian_pdf_log(\n",
        "                    x, self.mu_c[c : c + 1, :], self.log_sigma2_c[c : c + 1, :]\n",
        "                ).view(-1, 1)\n",
        "            )\n",
        "        return torch.cat(G, 1)\n",
        "\n",
        "    @staticmethod\n",
        "    def gaussian_pdf_log(x, mu, log_sigma2):\n",
        "        return -0.5 * (\n",
        "            torch.sum(\n",
        "                np.log(np.pi * 2)\n",
        "                + log_sigma2\n",
        "                + (x - mu).pow(2) / torch.exp(log_sigma2),\n",
        "                1,\n",
        "            )\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from torch.optim import Adam\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "batch_size=800\n",
        "n_clusters=10\n",
        "stat_dim=10\n",
        "\n",
        "DL_train, DL_test= get_data('MNIST',batch_size)\n",
        "vade=VaDE(n_clusters, stat_dim)\n",
        "vade.pre_train(DL_train, pre_epoch=2)\n",
        "vade.train(DL_train, epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "id": "_ARBS6vxlk24",
        "outputId": "e384843d-fbcc-424a-c8ec-1fbcc7b0cf34"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 1/3 [00:40<01:20, 40.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss=274.7342,LR=0.0020\n",
            "tensor(nan, grad_fn=<MinBackward1>) tensor(nan, grad_fn=<MaxBackward1>)\n",
            "tensor(nan, grad_fn=<MinBackward1>) tensor(nan, grad_fn=<MaxBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 1/3 [01:18<01:20, 40.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(nan, grad_fn=<MinBackward1>) tensor(nan, grad_fn=<MaxBackward1>)\n",
            "Loss=nan,LR=0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 2/3 [01:18<00:39, 39.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(nan, grad_fn=<MinBackward1>) tensor(nan, grad_fn=<MaxBackward1>)\n",
            "tensor(nan, grad_fn=<MinBackward1>) tensor(nan, grad_fn=<MaxBackward1>)\n",
            "tensor(nan, grad_fn=<MinBackward1>) tensor(nan, grad_fn=<MaxBackward1>)\n",
            "tensor(nan, grad_fn=<MinBackward1>) tensor(nan, grad_fn=<MaxBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 2/3 [01:21<00:40, 40.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(nan, grad_fn=<MinBackward1>) tensor(nan, grad_fn=<MaxBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-64cdd154ad8d>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mvade\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVaDE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstat_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mvade\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDL_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mvade\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDL_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-3eed7ace47a7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, dataloader, epochs, lr, gamma)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_bar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m                     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;31m# doing this so that it is consistent with all other datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;31m# to return a PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"L\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   3069\u001b[0m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array_interface__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3070\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3071\u001b[0;31m     \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3072\u001b[0m     \u001b[0mstrides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"strides\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3073\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test, y_test = [], []\n",
        "for x,y in DL_test:\n",
        "    x_test.append(x)\n",
        "    y_test.append(y)\n",
        "x_test = torch.cat(x_test, 0)\n",
        "y_test = torch.cat(y_test, 0)"
      ],
      "metadata": {
        "id": "0mlgwnMzwuCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "tsne = TSNE(n_components=2)\n",
        "z_test_pred = vade.encoder.encoder(x_test).detach().cpu().numpy()\n",
        "z_test_pred_tsne = tsne.fit_transform(z_test_pred)\n",
        "N=1000\n",
        "sns.scatterplot(x=z_test_pred_tsne[:N,0], y=z_test_pred_tsne[:N,1], hue=y_test[:N], palette=sns.color_palette(\"tab10\"))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "anY4PUh4DSVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fZG7kbWAtOAs"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "probs = vade.predict_proba(x_test)\n",
        "probs = probs.detach().cpu().numpy()\n",
        "y_pred_test = np.argmax(probs, axis=1)\n",
        "probs.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sw9fcoV4ytxX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}